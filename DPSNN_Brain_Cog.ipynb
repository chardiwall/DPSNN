{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chardiwall/DPSNN/blob/main/DPSNN_Brain_Cog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew-K_po4LhBB",
        "outputId": "cc454198-4801-4a62-a077-447b084553a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tonic\n",
        "!pip install -q opacus\n",
        "!pip install -q braincog\n",
        "!pip install -q timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cks8o1bjK_pN"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u39ByHoVLPl0",
        "outputId": "f6757af8-f258-4dd2-9bd9-49ab1f8fceb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:461: UserWarning: Overwriting resnet18 in registry with braincog.model_zoo.resnet.resnet18. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnet18(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:474: UserWarning: Overwriting resnet34 in registry with braincog.model_zoo.resnet.resnet34. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnet34(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:486: UserWarning: Overwriting resnet50 in registry with braincog.model_zoo.resnet.resnet50. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnet50(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:491: UserWarning: Overwriting resnet101 in registry with braincog.model_zoo.resnet.resnet101. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnet101(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:497: UserWarning: Overwriting resnet152 in registry with braincog.model_zoo.resnet.resnet152. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnet152(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:503: UserWarning: Overwriting resnext50_32x4d in registry with braincog.model_zoo.resnet.resnext50_32x4d. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnext50_32x4d(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:511: UserWarning: Overwriting resnext101_32x8d in registry with braincog.model_zoo.resnet.resnext101_32x8d. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def resnext101_32x8d(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:519: UserWarning: Overwriting wide_resnet50_2 in registry with braincog.model_zoo.resnet.wide_resnet50_2. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def wide_resnet50_2(pretrained=False, **kwargs):\n",
            "/usr/local/lib/python3.10/dist-packages/braincog/model_zoo/resnet.py:526: UserWarning: Overwriting wide_resnet101_2 in registry with braincog.model_zoo.resnet.wide_resnet101_2. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def wide_resnet101_2(pretrained=False, **kwargs):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import tonic\n",
        "from tonic import DiskCachedDataset\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "import abc\n",
        "from functools import partial\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from timm.models import register_model\n",
        "from braincog.base.node.node import *\n",
        "from braincog.base.connection.layer import *\n",
        "from braincog.base.encoder.encoder import *\n",
        "from braincog.model_zoo.base_module import BaseModule, BaseConvModule, BaseLinearModule\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "\n",
        "from braincog.base.node.node import *\n",
        "import warnings\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNfjwVFYLTAh"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHasJlQXLWPA"
      },
      "outputs": [],
      "source": [
        "MNIST_MEAN = 0.1307\n",
        "MNIST_STD = 0.3081\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
        "cifar100_mean = [0.5071, 0.4865, 0.4409]\n",
        "cifar100_std = [0.2673, 0.2563, 0.2761]\n",
        "DVSCIFAR10_MEAN_16 = [0.3290, 0.4507]\n",
        "DVSCIFAR10_STD_16 = [1.8398, 1.6549]\n",
        "\n",
        "DATA_DIR = '/data/datasets'\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"An abstract Dataset class wrapped around Pytorch Dataset class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices):\n",
        "        self.dataset = dataset\n",
        "        self.indices = [int(i) for i in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        x, y = self.dataset[self.indices[item]]\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def load_static_data(data_root, batch_size, dataset):\n",
        "    if dataset == 'cifar10':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV)])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV)])\n",
        "\n",
        "        train_data = datasets.CIFAR10(data_root, train=True, transform=transform_train, download=True)\n",
        "        test_data = datasets.CIFAR10(data_root, train=False, transform=transform_test, download=True)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_data,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_data,\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "    elif dataset == 'MNIST':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(MNIST_MEAN, MNIST_STD)])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(MNIST_MEAN, MNIST_STD)])\n",
        "\n",
        "        train_data = datasets.MNIST(data_root, train=True, transform=transform_train, download=True)\n",
        "        test_data = datasets.MNIST(data_root, train=False, transform=transform_test, download=True)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_data,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_data,\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "    elif dataset == 'FashionMNIST':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(MNIST_MEAN, MNIST_STD)])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(MNIST_MEAN, MNIST_STD)])\n",
        "\n",
        "        train_data = datasets.FashionMNIST(data_root, train=True, transform=transform_train, download=True)\n",
        "        test_data = datasets.FashionMNIST(data_root, train=False, transform=transform_test, download=True)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_data,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_data,\n",
        "            batch_size=batch_size,\n",
        "        )\n",
        "\n",
        "    return train_data, test_data, train_loader, test_loader\n",
        "\n",
        "\n",
        "def load_dvs10_data(batch_size, step, **kwargs):\n",
        "    size = kwargs['size'] if 'size' in kwargs else 48\n",
        "    sensor_size = tonic.datasets.CIFAR10DVS.sensor_size\n",
        "    train_transform = transforms.Compose([\n",
        "        # tonic.transforms.Denoise(filter_time=10000),\n",
        "        # tonic.transforms.DropEvent(p=0.1),\n",
        "        tonic.transforms.ToFrame(sensor_size=sensor_size, n_time_bins=step), ])\n",
        "    test_transform = transforms.Compose([\n",
        "        # tonic.transforms.Denoise(filter_time=10000),\n",
        "        tonic.transforms.ToFrame(sensor_size=sensor_size, n_time_bins=step), ])\n",
        "    train_dataset = tonic.datasets.CIFAR10DVS(os.path.join(DATA_DIR, 'DVS/DVS_Cifar10'), transform=train_transform)\n",
        "    test_dataset = tonic.datasets.CIFAR10DVS(os.path.join(DATA_DIR, 'DVS/DVS_Cifar10'), transform=test_transform)\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        lambda x: torch.tensor(x, dtype=torch.float),\n",
        "        lambda x: F.interpolate(x, size=[size, size], mode='bilinear', align_corners=True),\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        lambda x: torch.tensor(x, dtype=torch.float),\n",
        "        lambda x: F.interpolate(x, size=[size, size], mode='bilinear', align_corners=True),\n",
        "    ])\n",
        "\n",
        "    train_dataset = DiskCachedDataset(train_dataset,\n",
        "                                      cache_path=f'./dataset/dvs_cifar10/train_cache_{step}',\n",
        "                                      transform=train_transform)\n",
        "    test_dataset = DiskCachedDataset(train_dataset,\n",
        "                                     cache_path=f'./dataset/dvs_cifar10/test_cache_{step}',\n",
        "                                     transform=test_transform)\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    num_per_cls = num_train // 10\n",
        "    indices_train, indices_test = [], []\n",
        "    portion = kwargs['portion'] if 'portion' in kwargs else .9\n",
        "    for i in range(10):\n",
        "        indices_train.extend(\n",
        "            list(range(i * num_per_cls, round(i * num_per_cls + num_per_cls * portion))))\n",
        "        indices_test.extend(\n",
        "            list(range(round(i * num_per_cls + num_per_cls * portion), (i + 1) * num_per_cls)))\n",
        "    train_dataset = CustomDataset(train_dataset, np.array(indices_train))\n",
        "    test_dataset = CustomDataset(test_dataset, np.array(indices_test))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        pin_memory=True, drop_last=False, num_workers=1\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=batch_size,\n",
        "        pin_memory=True, drop_last=False, num_workers=1\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def load_nmnist_data(batch_size, step, **kwargs):\n",
        "    size = kwargs['size'] if 'size' in kwargs else 28\n",
        "    sensor_size = tonic.datasets.NMNIST.sensor_size\n",
        "    train_transform = transforms.Compose([\n",
        "        # tonic.transforms.Denoise(filter_time=10000),\n",
        "        # tonic.transforms.DropEvent(p=0.1),\n",
        "        tonic.transforms.ToFrame(sensor_size=sensor_size, n_time_bins=step), ])\n",
        "    test_transform = transforms.Compose([\n",
        "        # tonic.transforms.Denoise(filter_time=10000),\n",
        "        tonic.transforms.ToFrame(sensor_size=sensor_size, n_time_bins=step), ])\n",
        "    train_dataset = tonic.datasets.NMNIST(os.path.join(DATA_DIR, 'DVS/NMNIST'), transform=train_transform, train=True)\n",
        "    test_dataset = tonic.datasets.NMNIST(os.path.join(DATA_DIR, 'DVS/NMNIST'), transform=test_transform, train=False)\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        lambda x: torch.tensor(x, dtype=torch.float),\n",
        "        lambda x: F.interpolate(x, size=[size, size], mode='bilinear', align_corners=True),\n",
        "\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        lambda x: torch.tensor(x, dtype=torch.float),\n",
        "        lambda x: F.interpolate(x, size=[size, size], mode='bilinear', align_corners=True),\n",
        "    ])\n",
        "\n",
        "    train_dataset = DiskCachedDataset(train_dataset,\n",
        "                                      cache_path=f'./dataset/NMNIST/train_cache_{step}',\n",
        "                                      transform=train_transform)\n",
        "    test_dataset = DiskCachedDataset(test_dataset,\n",
        "                                     cache_path=f'./dataset/NMNIST/test_cache_{step}',\n",
        "                                     transform=test_transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        pin_memory=True, drop_last=False, num_workers=1\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=batch_size,\n",
        "        pin_memory=True, drop_last=False, num_workers=1\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlIQKV9XLz11"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWT1jT4ZLdXs"
      },
      "outputs": [],
      "source": [
        "class TEP(nn.Module):\n",
        "    def __init__(self, step, channel, device=None, dtype=None):\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(TEP, self).__init__()\n",
        "        self.step = step\n",
        "        self.gn = nn.GroupNorm(channel, channel)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = rearrange(x, '(t b) c w h -> t b c w h', t=self.step)\n",
        "        fire_rate = torch.mean(x, dim=0)\n",
        "        fire_rate = self.gn(fire_rate) + 1\n",
        "\n",
        "        x = x * fire_rate\n",
        "        x = rearrange(x, 't b c w h -> (t b) c w h')\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseConvNet(BaseModule, abc.ABC):\n",
        "    def __init__(self,\n",
        "                 step,\n",
        "                 input_channels,\n",
        "                 num_classes,\n",
        "                 encode_type,\n",
        "                 spike_output: bool,\n",
        "                 out_channels: list,\n",
        "                 block_depth: list,\n",
        "                 node_list: list,\n",
        "                 *args,\n",
        "                 **kwargs):\n",
        "        super().__init__(step, encode_type, *args, **kwargs)\n",
        "        self.num_cls = num_classes\n",
        "        self.spike_output = spike_output\n",
        "        self.groups = kwargs['n_groups'] if 'n_groups' in kwargs else 1\n",
        "        if not spike_output:\n",
        "            node_list.append(nn.Identity)\n",
        "            out_channels.append(self.num_cls)\n",
        "            self.vote = nn.Identity()\n",
        "            # self.vote = nn.Sequential(\n",
        "            #     nn.Linear(self.step, 32),\n",
        "            #     nn.ReLU(),\n",
        "            #     nn.Linear(32, 1)\n",
        "            # )\n",
        "        else:\n",
        "            out_channels.append(10 * self.num_cls)\n",
        "            self.vote = VotingLayer(10)\n",
        "\n",
        "        # check list length\n",
        "        if len(node_list) != len(out_channels):\n",
        "            raise ValueError\n",
        "        self.input_channels = input_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.block_depth = block_depth\n",
        "        self.node_list = node_list\n",
        "        self.feature = self._create_feature()\n",
        "        self.fc = self._create_fc()\n",
        "        if self.layer_by_layer:\n",
        "            self.flatten = nn.Flatten(start_dim=1)\n",
        "        else:\n",
        "            self.flatten = nn.Flatten()\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_feature(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_fc(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.encoder(inputs)\n",
        "        self.reset()\n",
        "        if not self.training:\n",
        "            self.fire_rate.clear()\n",
        "\n",
        "        if not self.layer_by_layer:\n",
        "            outputs = []\n",
        "            if self.warm_up:\n",
        "                step = 1\n",
        "            else:\n",
        "                step = self.step\n",
        "\n",
        "            for t in range(step):\n",
        "                x = inputs[t]\n",
        "                x = self.feature(x)\n",
        "                x = self.flatten(x)\n",
        "                x = self.fc(x)\n",
        "                x = self.vote(x)\n",
        "                outputs.append(x)\n",
        "\n",
        "            return sum(outputs) / len(outputs)\n",
        "            # outputs = torch.stack(outputs)\n",
        "            # outputs = rearrange(outputs, 't b c -> b c t')\n",
        "            # outputs = self.vote(outputs).squeeze()\n",
        "            # return outputs\n",
        "\n",
        "        else:\n",
        "            x = self.feature(inputs)\n",
        "            x = self.flatten(x)\n",
        "            x = self.fc(x)\n",
        "            if self.groups == 1:\n",
        "                x = rearrange(x, '(t b) c -> t b c', t=self.step).mean(0)\n",
        "            else:\n",
        "                x = rearrange(x, 'b (c t) -> t b c', t=self.step).mean(0)\n",
        "            x = self.vote(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "class LayerWiseConvModule(nn.Module):\n",
        "    \"\"\"\n",
        "    SNN卷积模块\n",
        "    :param in_channels: 输入通道数\n",
        "    :param out_channels: 输出通道数\n",
        "    :param kernel_size: kernel size\n",
        "    :param stride: stride\n",
        "    :param padding: padding\n",
        "    :param bias: Bias\n",
        "    :param node: 神经元类型\n",
        "    :param kwargs:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size=(3, 3),\n",
        "                 stride=(1, 1),\n",
        "                 padding=(1, 1),\n",
        "                 bias=False,\n",
        "                 node=LIFNode,\n",
        "                 step=6,\n",
        "                 **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if node is None:\n",
        "            raise TypeError\n",
        "\n",
        "        self.groups = kwargs['groups'] if 'groups' in kwargs else 1\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels * self.groups,\n",
        "                              out_channels=out_channels * self.groups,\n",
        "                              kernel_size=kernel_size,\n",
        "                              padding=padding,\n",
        "                              stride=stride,\n",
        "                              bias=bias)\n",
        "        self.gn = nn.GroupNorm(16, out_channels * self.groups)\n",
        "        self.node = partial(node, **kwargs)()\n",
        "        self.step = step\n",
        "        self.activation = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, '(t b) c w h -> t b c w h', t=self.step)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(self.step):\n",
        "            outputs.append(self.gn(self.conv(x[t])))\n",
        "        outputs = torch.stack(outputs)  # t b c w h\n",
        "        outputs = rearrange(outputs, 't b c w h -> (t b) c w h')\n",
        "        outputs = self.node(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class LayerWiseLinearModule(nn.Module):\n",
        "    \"\"\"\n",
        "    线性模块\n",
        "    :param in_features: 输入尺寸\n",
        "    :param out_features: 输出尺寸\n",
        "    :param bias: 是否有Bias, 默认 ``False``\n",
        "    :param node: 神经元类型, 默认 ``LIFNode``\n",
        "    :param args:\n",
        "    :param kwargs:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_features: int,\n",
        "                 out_features: int,\n",
        "                 bias=True,\n",
        "                 node=LIFNode,\n",
        "                 step=6,\n",
        "                 spike=False,\n",
        "                 *args,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        if node is None:\n",
        "            raise TypeError\n",
        "\n",
        "        self.groups = kwargs['groups'] if 'groups' in kwargs else 1\n",
        "        if self.groups == 1:\n",
        "            self.fc = nn.Linear(in_features=in_features,\n",
        "                                out_features=out_features, bias=bias)\n",
        "        else:\n",
        "            self.fc = nn.ModuleList()\n",
        "            for i in range(self.groups):\n",
        "                self.fc.append(nn.Linear(\n",
        "                    in_features=in_features,\n",
        "                    out_features=out_features,\n",
        "                    bias=bias\n",
        "                ))\n",
        "        self.node = partial(node, **kwargs)()\n",
        "        self.step = step\n",
        "        self.spike = spike\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.groups == 1:  # (t b) c\n",
        "            x = rearrange(x, '(t b) c -> t b c', t=self.step)\n",
        "            outputs = []\n",
        "            for t in range(self.step):\n",
        "                outputs.append(self.fc(x[t]))\n",
        "            outputs = torch.stack(outputs)  # t b c\n",
        "            outputs = rearrange(outputs, 't b c -> (t b) c')\n",
        "\n",
        "        else:  # b (c t)\n",
        "            x = rearrange(x, 'b (c t) -> t b c', t=self.groups)\n",
        "            outputs = []\n",
        "            for i in range(self.groups):\n",
        "                outputs.append(self.fc[i](x[i]))\n",
        "            outputs = torch.stack(outputs)  # t b c\n",
        "            outputs = rearrange(outputs, 't b c -> b (c t)')\n",
        "        if self.spike:\n",
        "            return self.node(outputs)\n",
        "        else:\n",
        "            return outputs\n",
        "\n",
        "\n",
        "class LayWiseConvNet(BaseConvNet):\n",
        "    def __init__(self,\n",
        "                 step,\n",
        "                 input_channels,\n",
        "                 num_classes,\n",
        "                 encode_type,\n",
        "                 spike_output: bool,\n",
        "                 out_channels: list,\n",
        "                 node_list: list,\n",
        "                 block_depth: list,\n",
        "                 *args,\n",
        "                 **kwargs):\n",
        "        super().__init__(step,\n",
        "                         input_channels,\n",
        "                         num_classes,\n",
        "                         encode_type,\n",
        "                         spike_output,\n",
        "                         out_channels,\n",
        "                         block_depth,\n",
        "                         node_list,\n",
        "                         *args,\n",
        "                         **kwargs)\n",
        "\n",
        "    def _create_feature(self):\n",
        "        feature_depth = len(self.node_list) - 1\n",
        "\n",
        "        feature = [LayerWiseConvModule(\n",
        "            self.input_channels * self.init_channel_mul, self.out_channels[0], node=self.node_list[0],\n",
        "            groups=self.groups, step=self.step)]\n",
        "        if self.block_depth[0] != 1:\n",
        "            feature.extend(\n",
        "                [LayerWiseConvModule(self.out_channels[0], self.out_channels[0], node=self.node_list[0],\n",
        "                                     groups=self.groups, step=self.step)] * (\n",
        "                        self.block_depth[0] - 1),\n",
        "            )\n",
        "        feature.append(TEP(channel=self.out_channels[0], step=self.step))\n",
        "        feature.append(nn.AvgPool2d(kernel_size=4, stride=2))\n",
        "        for i in range(1, feature_depth - 1):\n",
        "            feature.append(LayerWiseConvModule(\n",
        "                self.out_channels[i - 1], self.out_channels[i], node=self.node_list[i], groups=self.groups,\n",
        "                step=self.step))\n",
        "            if self.block_depth[i] != 1:\n",
        "                feature.extend(\n",
        "                    [LayerWiseConvModule(self.out_channels[i], self.out_channels[i], node=self.node_list[i],\n",
        "                                         groups=self.groups,\n",
        "                                         step=self.step)] * (\n",
        "                            self.block_depth[i] - 1),\n",
        "                )\n",
        "            feature.append(TEP(channel=self.out_channels[i], step=self.step))\n",
        "            feature.append(nn.AvgPool2d(kernel_size=4, stride=2))\n",
        "        feature.append(LayerWiseConvModule(\n",
        "            self.out_channels[-3], self.out_channels[-2], node=self.node_list[-2], groups=self.groups,\n",
        "            step=self.step))\n",
        "        if self.block_depth[feature_depth - 1] != 1:\n",
        "            feature.extend(\n",
        "                [LayerWiseConvModule(self.out_channels[-2], self.out_channels[-2], node=self.node_list[-2],\n",
        "                                     groups=self.groups,\n",
        "                                     step=self.step)] * (\n",
        "                        self.block_depth[feature_depth - 1] - 1),\n",
        "            )\n",
        "        feature.append(nn.AdaptiveAvgPool2d(1))\n",
        "\n",
        "        return nn.Sequential(*feature)\n",
        "\n",
        "    def _create_fc(self):\n",
        "        fc = nn.Sequential(\n",
        "            # NDropout(.5),\n",
        "            LayerWiseLinearModule(\n",
        "                self.out_channels[-2], self.out_channels[-1], node=self.node_list[-1], groups=self.groups,\n",
        "                step=self.step, spike=False)\n",
        "        )\n",
        "        return fc\n",
        "\n",
        "\n",
        "@register_model\n",
        "def cifar_convnet(step,\n",
        "                encode_type,\n",
        "                spike_output: bool,\n",
        "                node_type,\n",
        "                *args,\n",
        "                **kwargs):\n",
        "    # out_channels = [256, 256, 512, 1024]\n",
        "    out_channels = [64, 128, 128, 256]\n",
        "    block_depth = [2, 2, 2, 2]\n",
        "    # print(kwargs)\n",
        "    node_cls = partial(node_type, step=step, **kwargs)\n",
        "    # print(node_cls)\n",
        "    if spike_output:\n",
        "        node_list = [node_cls] * (len(out_channels) + 1)\n",
        "    else:\n",
        "        node_list = [node_cls] * (len(out_channels))\n",
        "\n",
        "    return LayWiseConvNet(step=step,\n",
        "                          input_channels=3,\n",
        "                          encode_type=encode_type,\n",
        "                          node_list=node_list,\n",
        "                          block_depth=block_depth,\n",
        "                          out_channels=out_channels,\n",
        "                          spike_output=spike_output,\n",
        "                          **kwargs)\n",
        "\n",
        "\n",
        "@register_model\n",
        "def dvs_convnet(step,\n",
        "                encode_type,\n",
        "                spike_output: bool,\n",
        "                node_type,\n",
        "                num_classes,\n",
        "                *args,\n",
        "                **kwargs):\n",
        "    out_channels = [64, 128, 256, 512, 1024]\n",
        "    block_depth = [2, 1, 2, 1, 2]\n",
        "\n",
        "    node_cls = partial(node_type, step=step, **kwargs)\n",
        "    if spike_output:\n",
        "        node_list = [node_cls] * (len(out_channels) + 1)\n",
        "        # node_list[-2] = partial(DoubleSidePLIFNode, step=step, **kwargs)\n",
        "    else:\n",
        "        node_list = [node_cls] * (len(out_channels))\n",
        "        # node_list[-1] = partial(DoubleSidePLIFNode, step=step, **kwargs)\n",
        "\n",
        "    return LayWiseConvNet(step=step,\n",
        "                          input_channels=2,\n",
        "                          num_classes=num_classes,\n",
        "                          encode_type=encode_type,\n",
        "                          node_list=node_list,\n",
        "                          block_depth=block_depth,\n",
        "                          out_channels=out_channels,\n",
        "                          spike_output=spike_output,\n",
        "                          **kwargs)\n",
        "\n",
        "\n",
        "@register_model\n",
        "class SimpleSNN(BaseModule, abc.ABC):\n",
        "    def __init__(self,\n",
        "                 channel=1,\n",
        "                 num_classes=10,\n",
        "                 step=8,\n",
        "                 node_type=LIFNode,\n",
        "                 encode_type='direct',\n",
        "                 *args,\n",
        "                 **kwargs):\n",
        "        super().__init__(step, encode_type, *args, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.node = node_type\n",
        "        init_channel = channel\n",
        "\n",
        "        self.feature = nn.Sequential(\n",
        "            LayerWiseConvModule(init_channel, 32, kernel_size=7, padding=0, node=self.node, step=step),\n",
        "            TEP(step=step, channel=32),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            LayerWiseConvModule(32, 64, kernel_size=4, padding=0, node=self.node, step=step),\n",
        "            TEP(step=step, channel=64),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            LayerWiseLinearModule(64 * 4 * 4, self.num_classes, node=self.node, spike=False, step=step),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = self.encoder(inputs)\n",
        "        self.reset()\n",
        "\n",
        "        if self.layer_by_layer:\n",
        "            x = self.feature(inputs)\n",
        "            x = self.fc(x)\n",
        "            x = rearrange(x, '(t b) c -> t b c', t=self.step).mean(0)\n",
        "            return x\n",
        "\n",
        "        else:\n",
        "            outputs = []\n",
        "            for t in range(self.step):\n",
        "                x = inputs[t]\n",
        "                x = self.feature(x)\n",
        "                x = self.fc(x)\n",
        "                outputs.append(x)\n",
        "\n",
        "            return sum(outputs) / len(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZJIMtmaMWCA"
      },
      "outputs": [],
      "source": [
        "# Precomputed characteristics of the dataset dataset\n",
        "torch.cuda.manual_seed(3154)\n",
        "\n",
        "batch_size = 512\n",
        "MAX_PHYSICAL_BATCH_SIZE = 32\n",
        "target_ep = 8\n",
        "c = 6\n",
        "epochs = 1\n",
        "\n",
        "step = 10\n",
        "delta = 1e-5\n",
        "devices = 4\n",
        "r = 1\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "disable_noise = False\n",
        "data_root = \"./dataset\"\n",
        "kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
        "dataset = 'NMNIST'\n",
        "# NMNIST, cifar10, dvs_cifar10, MNIST, FashionMNIST\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, privacy_engine):\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    losses = []\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for _batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # print(target)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        pred = output.argmax(\n",
        "            dim=1, keepdim=True\n",
        "        )  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    if not disable_noise:\n",
        "        epsilon = privacy_engine.get_epsilon(delta=delta)\n",
        "        print(\n",
        "            f\"Train Epoch: {epoch} \\t\"\n",
        "            f\"Loss: {np.mean(losses):.6f} \"\n",
        "        )\n",
        "        print(\"Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            correct,\n",
        "            len(train_loader.dataset),\n",
        "            100.0 * correct / len(train_loader.dataset), ))\n",
        "        print(\n",
        "              f\"(ε = {epsilon:.2f}, δ = {delta})\"\n",
        "              )\n",
        "    else:\n",
        "        print(f\"Train Epoch: {epoch} \\t Loss: {np.mean(losses):.6f}\")\n",
        "\n",
        "    return 100.0 * correct / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            len(test_loader.dataset),\n",
        "            100.0 * correct / len(test_loader.dataset),\n",
        "        )\n",
        "    )\n",
        "    return correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def run():\n",
        "    if dataset == 'dvs_cifar10':\n",
        "        train_loader, test_loader, train_data, test_data = load_dvs10_data(batch_size=batch_size, step=step)\n",
        "        # train_loader, test_loader, _, _ = get_dvsc10_data(batch_size=batch_size, step=step)\n",
        "    elif dataset == 'NMNIST':\n",
        "        train_loader, test_loader, train_data, test_data = load_nmnist_data(batch_size=batch_size, step=step)\n",
        "    else:\n",
        "        train_data, test_data, train_loader, test_loader = load_static_data(data_root, batch_size, dataset)\n",
        "\n",
        "    result = []\n",
        "    result_train = []\n",
        "    for _ in range(r):\n",
        "        if dataset == 'cifar10':\n",
        "            model = cifar_convnet(\n",
        "                step=step,\n",
        "                encode_type='direct',\n",
        "                node_type=LIFNode,\n",
        "                num_classes=10,\n",
        "                spike_output=False,\n",
        "                layer_by_layer=True,\n",
        "                act_fun=QGateGrad\n",
        "            )\n",
        "            model.to(device)\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[40], gamma=0.1, last_epoch=-1)\n",
        "\n",
        "        elif dataset == 'dvs_cifar10':\n",
        "            model = dvs_convnet(\n",
        "                step=step,\n",
        "                encode_type='direct',\n",
        "                node_type=LIFNode,\n",
        "                num_classes=10,\n",
        "                spike_output=False,\n",
        "                layer_by_layer=True,\n",
        "                act_fun=QGateGrad\n",
        "            )\n",
        "            model.to(device)\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15], gamma=1, last_epoch=-1)\n",
        "        elif dataset == 'NMNIST':\n",
        "            model = SimpleSNN(\n",
        "                channel=2,\n",
        "                step=step,\n",
        "                node_type=LIFNode,\n",
        "                act_fun=QGateGrad,\n",
        "                layer_by_layer=True,\n",
        "            )\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=0.005)\n",
        "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1, last_epoch=-1)\n",
        "\n",
        "        elif dataset == 'MNIST' or dataset == 'FashionMNIST':\n",
        "            model = SimpleSNN(\n",
        "                channel=1,\n",
        "                step=step,\n",
        "                node_type=LIFNode,\n",
        "                act_fun=QGateGrad,\n",
        "                layer_by_layer=True,\n",
        "            )\n",
        "            model.to(device)\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=0.005)\n",
        "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1, last_epoch=-1)\n",
        "        if not disable_noise:\n",
        "            privacy_engine = PrivacyEngine()\n",
        "            model, optimizer, data_loader = privacy_engine.make_private_with_epsilon(\n",
        "                module=model,\n",
        "                optimizer=optimizer,\n",
        "                data_loader=train_loader,\n",
        "                max_grad_norm=c,\n",
        "                epochs=epochs,\n",
        "                target_delta=delta,\n",
        "                target_epsilon=target_ep\n",
        "            )\n",
        "            with BatchMemoryManager(\n",
        "                    data_loader=data_loader,\n",
        "                    max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE,\n",
        "                    optimizer=optimizer\n",
        "            ) as memory_safe_data_loader:\n",
        "                # if 1:\n",
        "                for epoch in range(1, epochs + 1):\n",
        "                    result_train.append(train(model, device, memory_safe_data_loader, optimizer, epoch, privacy_engine))\n",
        "                    result.append(test(model, device, test_loader))\n",
        "                    scheduler.step()\n",
        "        else:\n",
        "            privacy_engine = PrivacyEngine()\n",
        "            model, optimizer, data_loader = privacy_engine.make_private(\n",
        "                module=model,\n",
        "                optimizer=optimizer,\n",
        "                data_loader=train_loader,\n",
        "                max_grad_norm=c,\n",
        "                noise_multiplier=0.0,\n",
        "            )\n",
        "            with BatchMemoryManager(\n",
        "                    data_loader=data_loader,\n",
        "                    max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE,\n",
        "                    optimizer=optimizer\n",
        "            ) as memory_safe_data_loader:\n",
        "                for epoch in range(1, epochs + 1):\n",
        "                    train(model, device, memory_safe_data_loader, optimizer, epoch, privacy_engine)\n",
        "                    result.append(test(model, device, test_loader))\n",
        "                    scheduler.step()\n",
        "    result = np.array(result).reshape((r, -1))\n",
        "    result_train = np.array(result_train).reshape((r, -1))\n",
        "    best_acc = np.mean(np.max(result, axis=1))\n",
        "    print(best_acc)\n",
        "    # np.save(file=f'./{dataset}/MP_test.npy', arr=result)\n",
        "    # np.save(file=f'./{dataset}/MP_train.npy', arr=result_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "70fa5146ee2d4ba7b3b1dafc33299f95",
            "b7e68e1910e3452281153c9515924408",
            "d0af75d8b9744c5780af82892b975535",
            "dafdda3901bc4b44a61a0f1ad48fd3fe",
            "8fc5e74214dc4afa95c6ad6159e0c12a",
            "2c68a89f9b1d4a069ae5d946677e1f5b",
            "e0c8161ec78f40b197a08b37a1f3aa0e",
            "d5f51dd3d496424498e31953f247e2bb",
            "98de7ce60d3c4c06893ff03ef910144a",
            "9ef10528755a4d1eb85b525e085f9b83",
            "aefe72ae22b2488aa72a6aeeb37e44e4"
          ]
        },
        "id": "oGuWrJIbywIx",
        "outputId": "3280da2e-20b6-44dd-de31-6127cc7e5a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to /data/datasets/DVS/NMNIST/NMNIST/train.zip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fa5146ee2d4ba7b3b1dafc33299f95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1011893601 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-fd67ade1b2e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_nmnist_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m1_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-0904d7f98134>\u001b[0m in \u001b[0;36mload_nmnist_data\u001b[0;34m(batch_size, step, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# tonic.transforms.Denoise(filter_time=10000),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         tonic.transforms.ToFrame(sensor_size=sensor_size, n_time_bins=step), ])\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtonic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DVS/NMNIST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtonic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DVS/NMNIST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tonic/datasets/nmnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, save_to, train, first_saccade_only, stabilize, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_on_system\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tonic/dataset.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"\"\"Downloads from a given url, places into target folder and verifies the file hash.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         download_and_extract_archive(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_on_system\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_md5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tonic/download_utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tonic/download_utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tonic/download_utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;31m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \"\"\"\n\u001b[1;32m   1200\u001b[0m         \u001b[0mManually\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train, test, _, _ = load_nmnist_data( 1_000, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qIsEGpLkNVj"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8EHmVY1krLk"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ7PRj69m-Ih"
      },
      "outputs": [],
      "source": [
        "x_, y_ = next(iter(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMuFZm9ErqrQ"
      },
      "outputs": [],
      "source": [
        "dic = {}\n",
        "\n",
        "for i in range(8):\n",
        "    rand_train = np.random.randint(0, 1_000, 1)[0]\n",
        "\n",
        "    train_data = x[rand_train, :, :, :]\n",
        "    train_target = y[rand_train]\n",
        "    for j in range(2):\n",
        "        name = 'group.'+str(i)\n",
        "        rand_test = np.random.randint(0, 1_000, 9 if j == 0 else 10)\n",
        "        data, target = 0, 0\n",
        "        if j == 0:\n",
        "            name += '.0.'\n",
        "            data = torch.cat((x_[rand_test, :, :, :, :], x[rand_train, :, :, : , :].unsqueeze(dim = 0)), dim = 0)\n",
        "            target = torch.cat((y_[rand_test], y[rand_train].unsqueeze(dim = 0)))\n",
        "        else:\n",
        "            name += '.1.'\n",
        "            data = x_[rand_test, :, :, :, :]\n",
        "            target = y_[rand_test]\n",
        "\n",
        "        dic[name + 'data'] = data\n",
        "        dic[name + 'target'] = target\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GHtIUBsrwF3"
      },
      "outputs": [],
      "source": [
        "dic['group.0.0.data'].shape, dic['group.0.0.target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbavYCVLiQUB"
      },
      "outputs": [],
      "source": [
        "dic['group.1.0.data'].shape, dic['group.1.0.target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiT2tgNMibWZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss = nn.CrossEntropyLoss().to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for i in range(8):\n",
        "        name = 'group.'+ str(i)\n",
        "        for j in range(2):\n",
        "            X = dic[name + '.'+str(j)+'.data'].to(device)\n",
        "            Y = dic[name + '.'+str(j)+'.target'].to(device)\n",
        "\n",
        "            output = model(X)\n",
        "\n",
        "            loss_val = loss(output, Y)\n",
        "            print(loss_val.item())\n",
        "\n",
        "        print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0rXCPSZjUWJ"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN182_F_iYMc"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for i in range(8):\n",
        "  for j in range(2):\n",
        "    group = 'group_'+str(i)+'.'+str(j)\n",
        "\n",
        "    if j == 0:\n",
        "\n",
        "      images = data[group][0][1:]\n",
        "      targets = data[group][1][1:]\n",
        "    else:\n",
        "      images = data[group][0]\n",
        "      targets = data[group][1]\n",
        "\n",
        "    group_data = Test_dataloader(images, targets)\n",
        "\n",
        "    group_loader = DataLoader(test, batch_size=10, shuffle = True)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      for X, y in group_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        output = model(X)\n",
        "\n",
        "        loss_val += criterion(output, y).item()  #\n",
        "      print(group, loss_val.item())\n",
        "      if group[-1] == 0:\n",
        "        lst0.append(loss_val)\n",
        "      else:\n",
        "        lst1.append(loss_val)\n",
        "\n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XSfmblliont"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c68a89f9b1d4a069ae5d946677e1f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fa5146ee2d4ba7b3b1dafc33299f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e68e1910e3452281153c9515924408",
              "IPY_MODEL_d0af75d8b9744c5780af82892b975535",
              "IPY_MODEL_dafdda3901bc4b44a61a0f1ad48fd3fe"
            ],
            "layout": "IPY_MODEL_8fc5e74214dc4afa95c6ad6159e0c12a"
          }
        },
        "8fc5e74214dc4afa95c6ad6159e0c12a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98de7ce60d3c4c06893ff03ef910144a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ef10528755a4d1eb85b525e085f9b83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aefe72ae22b2488aa72a6aeeb37e44e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e68e1910e3452281153c9515924408": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c68a89f9b1d4a069ae5d946677e1f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_e0c8161ec78f40b197a08b37a1f3aa0e",
            "value": " 61%"
          }
        },
        "d0af75d8b9744c5780af82892b975535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f51dd3d496424498e31953f247e2bb",
            "max": 1011893601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98de7ce60d3c4c06893ff03ef910144a",
            "value": 613327872
          }
        },
        "d5f51dd3d496424498e31953f247e2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafdda3901bc4b44a61a0f1ad48fd3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef10528755a4d1eb85b525e085f9b83",
            "placeholder": "​",
            "style": "IPY_MODEL_aefe72ae22b2488aa72a6aeeb37e44e4",
            "value": " 613327872/1011893601 [00:22&lt;00:13, 28980239.48it/s]"
          }
        },
        "e0c8161ec78f40b197a08b37a1f3aa0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}